{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c66bbb16-20e2-4c4d-8801-2448efb39789",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "from io import BytesIO\n",
    "import re\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c76055-5571-44c4-89f9-463e06bf5a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = extract_text('Umaima-Siddiqui-Resume.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3287c00c-c139-4ade-b846-e7ef46196828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Umaima Siddiqui\\nComputer System Engineer\\n\\numaima.siddiqui2000@gmail.com\\n\\n+92 3362644075\\n\\nModel Colony, Karachi\\n\\nPakistani\\n\\nhttps://www.linkedin.com/in/umaima-siddiqui-1b323b1ba/\\n\\nABOUT\\n\\nEDUCATION\\n\\nExcellent in time management, good communication, and\\nleadership  skills.  Always  enthusiastic  and  eager  to  learn\\nnew skills. A good listener and has experience working as\\npart of a team and individually.\\n\\nPROFESSIONAL EXPERIENCE\\n\\nXLOOP, Data Engineer\\n02.2023 – present | Karachi, Pakistan\\nWorking as a Data Engineer\\n\\nINFORMATION TECHNOLOGY SERVICES, Internee\\nKarachi, Pakistan\\nWorked in E-Publication Department\\n\\nPAKISTAN INTERNATIONAL AIRLINES, Internee\\nKarachi, Pakistan\\nWorked in Engineering Department as well as in IT \\nDepartment\\n\\nPROJECTS\\n\\nContract management system using Django\\n\\nGenerating test cases from user stories using \\nGenerative AI and Prompt Engineering\\n\\nOnline vs In-person appointments API\\n\\nAutomated Task Management System Using AI Based \\nRecommendation Engine (FYP)\\n\\nHouse Price Prediction using ML\\n\\nData Engineering Bootcamp, EMERITUS\\n03.2023 – 06.2023 | Karachi, Pakistan\\n\\nB.E. (Computer Systems)  CGPA 3.86, \\nDAWOOD UNIVERSITY OF ENGINEERING & TECHNOLOGY\\n2018 – 2022 | Karachi, Pakistan\\n\\nCertified Artificial Intelligence Developer, PIAIC\\n2019 – 2021 | Karachi, Pakistan\\nSecured 1st Position\\n\\nHSC. (Pre Engineering) A grade 73%, \\nGOVT DEGREE COLLEGE MALIR CANTT KARACHI\\n2016 – 2018 | Karachi, Pakistan\\n\\nTECH-SKILLS\\n\\nPython\\n\\nMySql\\n\\nDocker\\n\\nGitHub\\n\\nKafka-Pyspark\\n\\nDjango\\n\\nData Pipeline\\n\\nDeep Learning\\n\\nGenerative AI\\n\\nComputer Vision\\n\\nMNIST handwritten Digit Classification using ML\\n\\nLANGUAGES\\n\\nCOURSES\\n\\nGenerative AI with Large Language Models, Coursera\\n\\nDatabase Management Essentials, Coursera\\n\\nEnglish\\n\\nUrdu\\n\\nAI For Everyone, Coursera\\n\\nGoogle Data Analytics, Coursera\\n\\numaima.siddiqui2000@gmail.com\\x0c'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7664e9aa-9209-484d-bf27-52a88d91ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_items(input_list):\n",
    "    output_list = []\n",
    "    for item in input_list:\n",
    "        split_items = item.split('\\n')\n",
    "        # print('item', item)\n",
    "        # print('split_items', split_items)\n",
    "        output_list.extend(split_items)\n",
    "    return output_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f3f2fa-f39a-4adb-97ab-bb10cd3dc706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Umaima Siddiqui Computer System Engineer umaima.siddiqui2000@gmail.com +92 3362644075 Model Colony, Karachi Pakistani https://www.linkedin.com/in/umaima-siddiqui-1b323b1ba/ ABOUT EDUCATION Excellent in time management, good communication, and leadership  skills.  Always  enthusiastic  and  eager  to  learn new skills. A good listener and has experience working as part of a team and individually. PROFESSIONAL EXPERIENCE XLOOP, Data Engineer 02.2023 – present | Karachi, Pakistan Working as a Data Engineer INFORMATION TECHNOLOGY SERVICES, Internee Karachi, Pakistan Worked in E-Publication Department PAKISTAN INTERNATIONAL AIRLINES, Internee Karachi, Pakistan Worked in Engineering Department as well as in IT  Department PROJECTS Contract management system using Django Generating test cases from user stories using  Generative AI and Prompt Engineering Online vs In-person appointments API Automated Task Management System Using AI Based  Recommendation Engine (FYP) House Price Prediction using ML Data Engineering Bootcamp, EMERITUS 03.2023 – 06.2023 | Karachi, Pakistan B.E. (Computer Systems)  CGPA 3.86,  DAWOOD UNIVERSITY OF ENGINEERING & TECHNOLOGY 2018 – 2022 | Karachi, Pakistan Certified Artificial Intelligence Developer, PIAIC 2019 – 2021 | Karachi, Pakistan Secured 1st Position HSC. (Pre Engineering) A grade 73%,  GOVT DEGREE COLLEGE MALIR CANTT KARACHI 2016 – 2018 | Karachi, Pakistan TECH-SKILLS Python MySql Docker GitHub Kafka-Pyspark Django Data Pipeline Deep Learning Generative AI Computer Vision MNIST handwritten Digit Classification using ML LANGUAGES COURSES Generative AI with Large Language Models, Coursera Database Management Essentials, Coursera English Urdu AI For Everyone, Coursera Google Data Analytics, Coursera umaima.siddiqui2000@gmail.com'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_text_list = resume_text.split(\"\\n\\n\")\n",
    "resume_text_list = [item.strip() for item in resume_text_list]\n",
    "# resume_text_list = [item.split(\"\\n\") for item in resume_text_list]\n",
    "resume_text_list = split_list_items(resume_text_list)\n",
    "resume_text_list = [item.replace('\\xa0', ' ') for item in resume_text_list]\n",
    "result_string = ' '.join(resume_text_list)\n",
    "result_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db68ed4a-bf5a-4d70-a6fb-c61697e0a4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------resume_text_list ['Contact', '+923362166817 (Mobile)\\naadiisarki@gmail.com', 'www.linkedin.com/in/muhammad-\\nadil-sarki (LinkedIn)', 'Top Skills', 'Problem Solving', 'Data Analysis', 'Analytical Skills', 'Muhammad Adil Sarki', 'Data Scientist at Covolv.ai\\nKarāchi, Sindh, Pakistan', 'Experience', 'covolv.ai\\nData Scientist\\nFebruary 2022\\xa0-\\xa0Present\\xa0(2 years 4 months)\\nKarāchi, Sindh, Pakistan', 'Autonomous Car driving.', 'Pakistan State Oil\\nTrainee officer\\nMay 2021\\xa0-\\xa0January 2022\\xa0(9 months)\\nKarāchi, Sindh, Pakistan', 'Aptech\\nCourse Instructor\\nJanuary 2021\\xa0-\\xa0March 2021\\xa0(3 months)\\nKarāchi, Sindh, Pakistan', 'Delivered theoretical & practical knowledge of programming', 'Education', 'Dawood University of Engineering and Technology', 'Bachelor of Engineering - BE,\\xa0Computer Science\\xa0·\\xa0(2017\\xa0-\\xa02021)', 'Page 1 of 1', ''] \n",
      "\n",
      "\n",
      "====== unique_dates ['January 2021', 'March 2021', 'February 2022', 'May 2021', 'January 2022']\n",
      "============= exp_dates ['January 2021', 'March 2021', 'February 2022', 'May 2021', 'January 2022']\n"
     ]
    }
   ],
   "source": [
    "resume_headings = [\n",
    "    \"education\",\n",
    "    \"contact information\",\n",
    "    \"contact\",\n",
    "    \"objective or summary\",\n",
    "    \"skills\",\n",
    "    \"certifications\",\n",
    "    \"projects\",\n",
    "    \"volunteer work\",\n",
    "    \"awards and honors\",\n",
    "    \"languages\",\n",
    "    \"summary\",\n",
    "]\n",
    "\n",
    "resume_text_list = resume_text.split(\"\\n\\n\")\n",
    "resume_text_list = [item.strip() for item in resume_text_list]\n",
    "\n",
    "print('----------------resume_text_list', resume_text_list, '\\n\\n')\n",
    "\n",
    "exp_sen = \"\"\n",
    "if \"Experience\" in resume_text_list:\n",
    "    exp_ind = resume_text_list.index('Experience')\n",
    "    for section in resume_text_list:\n",
    "        if section.lower() in resume_headings:\n",
    "            sec_ind = resume_text_list.index(section)\n",
    "            if exp_ind < sec_ind:\n",
    "                only_exp = resume_text_list[exp_ind:sec_ind]\n",
    "            else:\n",
    "                only_exp = resume_text_list[exp_ind:]\n",
    "            if only_exp:\n",
    "                exp_sen = ', '.join(only_exp)\n",
    "            break\n",
    "else:\n",
    "    exp_sen = '\\n'.join(resume_text_list)\n",
    "# print(exp_sen)\n",
    "exp_dates = extract_experience_dates(exp_sen)\n",
    "print('============= exp_dates', exp_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a01bd4be-2ab7-4edd-8987-89744df22f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datefinder\n",
      "  Downloading datefinder-0.7.3-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: regex>=2017.02.08 in d:\\python_enviroments\\gen_env_3.11.5\\lib\\site-packages (from datefinder) (2023.12.25)\n",
      "Requirement already satisfied: python-dateutil>=2.4.2 in d:\\python_enviroments\\gen_env_3.11.5\\lib\\site-packages (from datefinder) (2.8.2)\n",
      "Requirement already satisfied: pytz in d:\\python_enviroments\\gen_env_3.11.5\\lib\\site-packages (from datefinder) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\python_enviroments\\gen_env_3.11.5\\lib\\site-packages (from python-dateutil>=2.4.2->datefinder) (1.16.0)\n",
      "Downloading datefinder-0.7.3-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: datefinder\n",
      "Successfully installed datefinder-0.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install datefinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57874f66-3f74-4b54-b150-09e004184281",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_text = extract_text('Profile.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da9acc0a-e722-4c2f-ae03-032eebb87f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contact +923362166817 (Mobile) aadiisarki@gmail.com www.linkedin.com/in/muhammad- adil-sarki (LinkedIn) Top Skills Problem Solving Data Analysis Analytical Skills Muhammad Adil Sarki Data Scientist at Covolv.ai Karāchi, Sindh, Pakistan Experience covolv.ai Data Scientist February 2022 - Present (2 years 4 months) Karāchi, Sindh, Pakistan Autonomous Car driving. Pakistan State Oil Trainee officer May 2021 - January 2022 (9 months) Karāchi, Sindh, Pakistan Aptech Course Instructor January 2021 - March 2021 (3 months) Karāchi, Sindh, Pakistan Delivered theoretical & practical knowledge of programming Education Dawood University of Engineering and Technology Bachelor of Engineering - BE, Computer Science · (2017 - 2021) Page 1 of 1 \n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "from io import BytesIO\n",
    "import re\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# resume_text\n",
    "resume_text = extract_text('Profile.pdf')\n",
    "def split_list_items(input_list):\n",
    "    output_list = []\n",
    "    for item in input_list:\n",
    "        split_items = item.split('\\n')\n",
    "        # print('item', item)\n",
    "        # print('split_items', split_items)\n",
    "        output_list.extend(split_items)\n",
    "    return output_list\n",
    "resume_text_list = resume_text.split(\"\\n\\n\")\n",
    "resume_text_list = [item.strip() for item in resume_text_list]\n",
    "# resume_text_list = [item.split(\"\\n\") for item in resume_text_list]\n",
    "resume_text_list = split_list_items(resume_text_list)\n",
    "resume_text_list = [item.replace('\\xa0', ' ') for item in resume_text_list]\n",
    "result_string = ' '.join(resume_text_list)\n",
    "print(result_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933b3ad-1ec5-4799-86b8-f2e56ea5d80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "3873c568-473d-4849-9d2b-feb91b502ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['May 1989', 'January 2017 - September 2018', 'January 2015 - December 2016', 'September 2013 - October 2014', 'April 2011 - September 2012']\n",
      "date_range ['January 2017 - September 2018']\n",
      "Total months: 21\n",
      "date_range ['January 2015 - December 2016']\n",
      "Total months: 24\n",
      "date_range ['September 2013 - October 2014']\n",
      "Total months: 14\n",
      "date_range ['April 2011 - September 2012']\n",
      "Total months: 18\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import re\n",
    "from pdfminer.high_level import extract_text\n",
    "from io import BytesIO\n",
    "import re\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# resume_text\n",
    "# resume_text = extract_text('Profile.pdf')\n",
    "resume_text = extract_text('Haymen CV.pdf')\n",
    "\n",
    "def split_list_items(input_list):\n",
    "    output_list = []\n",
    "    for item in input_list:\n",
    "        split_items = item.split('\\n')\n",
    "        # print('item', item)\n",
    "        # print('split_items', split_items)\n",
    "        output_list.extend(split_items)\n",
    "    return output_list\n",
    "resume_text_list = resume_text.split(\"\\n\\n\")\n",
    "resume_text_list = [item.strip() for item in resume_text_list]\n",
    "# resume_text_list = [item.split(\"\\n\") for item in resume_text_list]\n",
    "resume_text_list = split_list_items(resume_text_list)\n",
    "resume_text_list = [item.replace('\\xa0', ' ') for item in resume_text_list]\n",
    "result_string = ' '.join(resume_text_list)\n",
    "# print(result_string)\n",
    "\n",
    "# Regular expression to match the format \"Month Year - Month Year\"\n",
    "date_pattern1 = r'(?:January|February|March|April|May|June|July|August|September|October|November|December) \\d{4} - Present'\n",
    "\n",
    "date_pattern2 = r'(?:January|February|March|April|May|June|July|August|September|October|November|December) \\d{4} - (?:January|February|March|April|May|June|July|August|September|October|November|December) \\d{4}'\n",
    "\n",
    "date_pattern3 = r'(?:January|February|March|April|May|June|July|August|September|October|November|December) \\d{4}'\n",
    "\n",
    "\n",
    "combined_pattern = f'({date_pattern1})|({date_pattern2})|({date_pattern3})'\n",
    "\n",
    "\n",
    "matches = re.findall(combined_pattern, result_string)\n",
    "\n",
    "matches = [item for tup in matches for item in tup if item]\n",
    "\n",
    "# Print matches\n",
    "print(matches)\n",
    "\n",
    "def calculate_months(date_range):\n",
    "    # Remove unnecessary characters and split the date range\n",
    "    print('date_range', date_range)\n",
    "    date_range = date_range[0]\n",
    "    start_date_str, end_date_str = date_range.split(' - ')\n",
    "\n",
    "    # Define a dictionary to convert month names to numbers\n",
    "    month_dict = {\n",
    "        'January': 1, 'February': 2, 'March': 3, 'April': 4, \n",
    "        'May': 5, 'June': 6, 'July': 7, 'August': 8, \n",
    "        'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "    }\n",
    "\n",
    "    # Parse the start date\n",
    "    start_month_str, start_year_str = start_date_str.split(' ')\n",
    "    start_month = month_dict[start_month_str]\n",
    "    start_year = int(start_year_str)\n",
    "    start_date = datetime(start_year, start_month, 1)\n",
    "\n",
    "    # Parse the end date\n",
    "    end_month_str, end_year_str = end_date_str.split(' ')\n",
    "    end_month = month_dict[end_month_str]\n",
    "    end_year = int(end_year_str)\n",
    "    end_date = datetime(end_year, end_month, 1)\n",
    "\n",
    "    # Calculate the difference in months\n",
    "    total_months = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)+1\n",
    "\n",
    "    return total_months\n",
    "\n",
    "for i in matches[1:]:\n",
    "    # print(i)\n",
    "    months = calculate_months([i])\n",
    "    print(f'Total months: {months}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65709b4f-f234-4c8f-b4da-d303193f1c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['May 2021 - January 2022', 'January 2021 - March 2021']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = ['February 2022 - Present', 'May 2021 - January 2022', 'January 2021 - March 2021']\n",
    "# a[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040a1c77-aba5-4372-86d9-8bdb20a0076b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63b0d96b-b4aa-4a3f-8735-d6c322befe1f",
   "metadata": {},
   "source": [
    "# Extract Experience section "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ba41645f-8c62-4ed0-83fd-3d82d16d2959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from fastapi import FastAPI, File, UploadFile, Form\n",
    "from fastapi.responses import JSONResponse\n",
    "from pdfminer.high_level import extract_text\n",
    "from io import BytesIO\n",
    "import re\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "def extract_experience_dates(resume_text):\n",
    "    date_patterns = [\n",
    "        r'\\d{2}/\\d{4}',  # Matches MM/YYYY\n",
    "        r'\\d{2}/\\d{2}/\\d{4}',  # Matches DD/MM/YYYY\n",
    "        r'\\w+ \\d{4}',  # Matches Month YYYY (e.g., \"March 2020\")\n",
    "        r'\\d{4}-\\d{4}',  # Matches YYYY-YYYY\n",
    "    ]\n",
    "\n",
    "    extracted_dates = []\n",
    "\n",
    "    for pattern in date_patterns:\n",
    "        dates = re.findall(pattern, resume_text)\n",
    "        extracted_dates.extend(dates)\n",
    "\n",
    "    month_mapping = {\n",
    "        'january': '01', 'february': '02', 'march': '03', 'april': '04',\n",
    "        'may': '05', 'june': '06', 'july': '07', 'august': '08',\n",
    "        'september': '09', 'october': '10', 'november': '11', 'december': '12',\n",
    "        'jan': '01', 'feb': '02', 'mar': '03', 'apr': '04',\n",
    "        'may': '05', 'jun': '06', 'jul': '07', 'aug': '08',\n",
    "        'sep': '09', 'oct': '10', 'nov': '11', 'dec': '12'\n",
    "    }\n",
    "\n",
    "    def convert_date(date_str):\n",
    "        for month_name, month_num in month_mapping.items():\n",
    "            if month_name in date_str.lower():\n",
    "                date_str = date_str.lower().replace(month_name, month_num)\n",
    "                break\n",
    "        return date_str\n",
    "\n",
    "    unique_dates = list(set(extracted_dates))\n",
    "    # print('====== unique_dates', unique_dates)\n",
    "    return unique_dates\n",
    "def split_list_items(input_list):\n",
    "    output_list = []\n",
    "    for item in input_list:\n",
    "        split_items = item.split('\\n')\n",
    "        # print('item', item)\n",
    "        # print('split_items', split_items)\n",
    "        output_list.extend(split_items)\n",
    "    return output_list\n",
    "def extract_experience(resume_text):\n",
    "    resume_headings = [\n",
    "        \"education\",\n",
    "        \"contact information\",\n",
    "        \"contact\",\n",
    "        \"objective or summary\",\n",
    "        \"skills\",\n",
    "        \"certifications\",\n",
    "        \"projects\",\n",
    "        \"volunteer work\",\n",
    "        \"awards and honors\",\n",
    "        \"languages\",\n",
    "        \"summary\",\n",
    "        \"skills &\",\n",
    "        \"expertise\",\n",
    "        \"languagues\",\n",
    "        \"interests\"\n",
    "    ]\n",
    "\n",
    "    resume_text_list = resume_text.split(\"\\n\\n\")\n",
    "    resume_text_list = [item.strip() for item in resume_text_list]\n",
    "    # resume_text_list = [item.split(\"\\n\") for item in resume_text_list]\n",
    "    resume_text_list = split_list_items(resume_text_list)\n",
    "    resume_text_list = [item.replace('\\xa0', ' ') for item in resume_text_list]\n",
    "    resume_text_list = [item.lower() for item in resume_text_list]\n",
    "    print('***** resume_text_list', resume_text_list, '\\n\\n')\n",
    "    \n",
    "    result_string = ' '.join(resume_text_list)\n",
    "    # result_string = ' '.join(resume_text_list)\n",
    "\n",
    "    \n",
    "    # print('resume_text_list:   ', resume_text_list)\n",
    "    exp_sen = \"\"\n",
    "    if \"experience\" in resume_text_list:\n",
    "        exp_ind = resume_text_list.index('experience')\n",
    "        for section in resume_text_list:\n",
    "            if section.lower() in resume_headings:\n",
    "                sec_ind = resume_text_list.index(section)\n",
    "                # print('******* resume_text_list[sec_ind]', resume_text_list[sec_ind])\n",
    "                # print('******* resume_text_list[exp_ind]', resume_text_list[exp_ind])\n",
    "                \n",
    "                # print('******* exp_ind', exp_ind)\n",
    "                # print('******* sec_ind', sec_ind)\n",
    "                \n",
    "                if exp_ind < sec_ind:\n",
    "                    only_exp = resume_text_list[exp_ind:sec_ind]\n",
    "                    # print('####### if only_exp: ', only_exp)\n",
    "                else:\n",
    "                    only_exp = resume_text_list[exp_ind:]\n",
    "                    exists = any(item in only_exp for item in resume_headings)\n",
    "                    if exists:\n",
    "                        # print('if exists', exists)\n",
    "                    \n",
    "                        # print('####### else only_exp: ', only_exp)\n",
    "                        # if \"experience\" in only_exp:\n",
    "                        exp_ind2 = only_exp.index('experience')\n",
    "                        for j in only_exp:\n",
    "                            if j.lower() in resume_headings:\n",
    "                                # print('sub section: ', j)\n",
    "                                sec_ind2 = only_exp.index(j)\n",
    "                                # print('******* 2222resume_text_list[sec_ind]', only_exp[sec_ind2])\n",
    "                                # print('******* 2222resume_text_list[exp_ind]', only_exp[exp_ind2])\n",
    "                                \n",
    "                                # print('******* 2222exp_ind', exp_ind2)\n",
    "                                # print('******* 2222sec_ind', sec_ind2)\n",
    "                                if exp_ind2 < sec_ind2:\n",
    "                                    only_exp2 = only_exp[exp_ind2:sec_ind2]\n",
    "                                    # print('*************** *####### if only_exp: ', only_exp2)\n",
    "                                    # exp_sen = ', '.join(only_exp2)\n",
    "                                    return only_exp2\n",
    "                                break\n",
    "                                    # if only_exp2:\n",
    "                                    #     exp_sen = ', '.join(only_exp2)\n",
    "                                    # break\n",
    "                            \n",
    "                    else:\n",
    "                        exp_sen = ', '.join(only_exp)\n",
    "                    break\n",
    "    else:\n",
    "        # exp_sen = '\\n'.join(resume_text_list)\n",
    "        resume_text_list\n",
    "    # print('*********** exp_sen:', exp_sen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0646eb97-d274-405f-ae43-e0dde99292f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** resume_text_list ['hayman mohammed', 'date of birth: 2 may 1989', 'nationality: iraqi/kurdish', 'gender: male', 'marital status: single', 'email: hayman.salih@diag.uniroma1.it', 'telephone number: +39 (393) 025-1989', 'permanent address: via catania 1, guidonia montecelio rm /italy.', 'profile', 'education', 'i worked in several local and international companies in kurdistan for more than 6', 'years. during this time i got many professional expertise in the field of information', 'technology, networking, website management, traffic engineering (qos) and', 'computers maintenance. my professional and academic background enabled me to', 'deal with the complex issues and solve them with compatible standards.', 'phd in computer', 'engineering', 'sapienza university of roma (rome, italy)', 'phd candidate, department of computer, control and', 'management engineering “antonio ruberti” 2017-until now', 'master in computer', 'engineering', 'eastern mediterranean university (famagusta, cyprus)', \"master's degree, computer engineering, 2012 – 2014\", 'thesis title: a comparative study on palmprint recognition', 'supervisor: ass. prof. dr. onsen toygar', 'bsc in computer', ' science', 'university of picardie jules verne upjv (amiens, france)', 'bachelor of computer science (bsc), 2006 – 2011', 'experience', 'remote network', 'operator', 'graduation project: local network management, design and', 'implementation', 'cellnet telecom  (january 2017 - september 2018)', 'designing stable and reliable wireless network.', 'provide professional network topology and diagram for stable internet', 'service.', 'establish wireless network with ubnt, mikrotik products.', 'installation and configuration ptp & ptm ubnt mikrotik infrastructure of', 'the wireless and their complex connectivity and redundancy connectivity', 'between all base stations with big capacity of bandwidth stable', 'connectivity between all base stations.', 'installation configuration ubnt devices, air fiber rocket dish, sectors', 'and directional sectors.', 'mikrotik products wireless base stations base box with antenna router', 'board 1100 and ccr cloud router 1036 their installation configuration for', 'deferent requirements filtering bandwidth controller ', 'failover load balancer redundancy hotspots wireless dhcp bgp', 'configuration broadband and hotspots infrastructure and the radius', 'authentication.', 'prtg installation for monitoring network stability and bandwidth usage.', 'experience', 'noc senior engineer', 'alsardfiber (january 2015 - december 2016)', 'serve as primary responder for all server issues and customer', 'complaints, monitoring the progress of events and supplying the', 'client, partner or vendor with updates.', 'monitor all of the global edge cast servers, applications, network', 'devices and connections along with customer traffic, using', 'specific custom built tools.', 'work with the system and network administration teams to', 'resolve complex issues within specific service level agreement', 'times.', 'work directly with edge cast customer to resolve technical', 'issues and questions.', 'provide thorough research of customer facing issues and', 'provide report escalation teams prior to escalation.', 'update customers regularly on ongoing trouble tickets and', 'provide full report issues.', 'applying updated solutions for the internal issues.', 'daily bandwidth calculation for each customer independently.', 'installation and configuration of point to point networks (rockets,', 'nanostations, airfiber and other ubnt devices).', 'checking the main fiber optic cores incase of having any outage', 'and determining the distance of outage by using otdr.', 'writing nightly reports of all activities and solved issues during', 'the night working hours.', 'eastern mediterranean university  (september 2013 -', 'october 2014)', 'providing technology assistance to the department.', 'maintain staff workstations and peripherals, including', 'applying and updating virus detection software, and', 'multimedia applications.', 'applying system tools for management staff.', 'troubleshoot software and hardware problems on staff', 'equipment.', 'performing equipment repairs as necessary.', 'performing other duties as assigned', 'research assistant', 'experience', 'it/network', 'engineer', 'teknokar co.  (april 2011 - september 2012)', 'handling vsat hub/technical escalations and resolving', 'issues', 'monitoring region operations directly and remotely on', 'installation coordination, providing solutions to regions on', 'technical escalations.', 'negotiate prices with satellite providers', 'prepare monthly bandwidth reports for all hubs and', 'discuss and advise management.', 'installing, supporting and maintaining new server', 'hardware and software infrastructure;', 'setting up user accounts, permissions, and passwords;', 'monitoring network usage;', 'analyzing and resolving faults, ranging from a major', 'system crash to a forgotten password;', 'providing training and technical support for users with', 'varying levels of it knowledge and competence;', 'supervising other staff, such as help-desk technicians;', 'presenting company to potential clients through direct', 'communication in face to face meetings, telephone calls', 'and emails', 'troubleshooting system and network problems and', 'diagnosing and solving hardware or software faults;', 'maintenance of network infrastructure and architecture', 'maintain a thorough understanding of the basics behind', 'the internet and its workings (dns, security, ip routing,', 'http, vpn, email routing, spam, etc.', 'skills &', 'expertise', 'digital image processing, design patterns, java, matlab, c++, c, microsoft office,', 'windows, html, it management, it solutions, project management, marketing,', 'multimedia, wireless communications systems, wireless networking, systems', 'analysis, data mining, statistics, cisco technologies, artificial intelligence.', 'languagues', 'interests', 'kurdish', 'english', 'arabic', 'turkish', 'native or bilingual proficiency', 'full professional proficiency', 'full professional proficiency', 'professional working  proficiency', 'reading, traveling, digital photography, listening to music, watching movies.', 'notes', 'i certify that the above information is true, complete, and correct to the best of', 'my knowledge and belief. otherwise i’ll undertake all consequent results.', ' i’m ready to provide you all documents, papers, and certifications, which', 'support the above statement', 'references are available upon request', ''] \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['experience',\n",
       " 'remote network',\n",
       " 'operator',\n",
       " 'graduation project: local network management, design and',\n",
       " 'implementation',\n",
       " 'cellnet telecom  (january 2017 - september 2018)',\n",
       " 'designing stable and reliable wireless network.',\n",
       " 'provide professional network topology and diagram for stable internet',\n",
       " 'service.',\n",
       " 'establish wireless network with ubnt, mikrotik products.',\n",
       " 'installation and configuration ptp & ptm ubnt mikrotik infrastructure of',\n",
       " 'the wireless and their complex connectivity and redundancy connectivity',\n",
       " 'between all base stations with big capacity of bandwidth stable',\n",
       " 'connectivity between all base stations.',\n",
       " 'installation configuration ubnt devices, air fiber rocket dish, sectors',\n",
       " 'and directional sectors.',\n",
       " 'mikrotik products wireless base stations base box with antenna router',\n",
       " 'board 1100 and ccr cloud router 1036 their installation configuration for',\n",
       " 'deferent requirements filtering bandwidth controller ',\n",
       " 'failover load balancer redundancy hotspots wireless dhcp bgp',\n",
       " 'configuration broadband and hotspots infrastructure and the radius',\n",
       " 'authentication.',\n",
       " 'prtg installation for monitoring network stability and bandwidth usage.',\n",
       " 'experience',\n",
       " 'noc senior engineer',\n",
       " 'alsardfiber (january 2015 - december 2016)',\n",
       " 'serve as primary responder for all server issues and customer',\n",
       " 'complaints, monitoring the progress of events and supplying the',\n",
       " 'client, partner or vendor with updates.',\n",
       " 'monitor all of the global edge cast servers, applications, network',\n",
       " 'devices and connections along with customer traffic, using',\n",
       " 'specific custom built tools.',\n",
       " 'work with the system and network administration teams to',\n",
       " 'resolve complex issues within specific service level agreement',\n",
       " 'times.',\n",
       " 'work directly with edge cast customer to resolve technical',\n",
       " 'issues and questions.',\n",
       " 'provide thorough research of customer facing issues and',\n",
       " 'provide report escalation teams prior to escalation.',\n",
       " 'update customers regularly on ongoing trouble tickets and',\n",
       " 'provide full report issues.',\n",
       " 'applying updated solutions for the internal issues.',\n",
       " 'daily bandwidth calculation for each customer independently.',\n",
       " 'installation and configuration of point to point networks (rockets,',\n",
       " 'nanostations, airfiber and other ubnt devices).',\n",
       " 'checking the main fiber optic cores incase of having any outage',\n",
       " 'and determining the distance of outage by using otdr.',\n",
       " 'writing nightly reports of all activities and solved issues during',\n",
       " 'the night working hours.',\n",
       " 'eastern mediterranean university  (september 2013 -',\n",
       " 'october 2014)',\n",
       " 'providing technology assistance to the department.',\n",
       " 'maintain staff workstations and peripherals, including',\n",
       " 'applying and updating virus detection software, and',\n",
       " 'multimedia applications.',\n",
       " 'applying system tools for management staff.',\n",
       " 'troubleshoot software and hardware problems on staff',\n",
       " 'equipment.',\n",
       " 'performing equipment repairs as necessary.',\n",
       " 'performing other duties as assigned',\n",
       " 'research assistant',\n",
       " 'experience',\n",
       " 'it/network',\n",
       " 'engineer',\n",
       " 'teknokar co.  (april 2011 - september 2012)',\n",
       " 'handling vsat hub/technical escalations and resolving',\n",
       " 'issues',\n",
       " 'monitoring region operations directly and remotely on',\n",
       " 'installation coordination, providing solutions to regions on',\n",
       " 'technical escalations.',\n",
       " 'negotiate prices with satellite providers',\n",
       " 'prepare monthly bandwidth reports for all hubs and',\n",
       " 'discuss and advise management.',\n",
       " 'installing, supporting and maintaining new server',\n",
       " 'hardware and software infrastructure;',\n",
       " 'setting up user accounts, permissions, and passwords;',\n",
       " 'monitoring network usage;',\n",
       " 'analyzing and resolving faults, ranging from a major',\n",
       " 'system crash to a forgotten password;',\n",
       " 'providing training and technical support for users with',\n",
       " 'varying levels of it knowledge and competence;',\n",
       " 'supervising other staff, such as help-desk technicians;',\n",
       " 'presenting company to potential clients through direct',\n",
       " 'communication in face to face meetings, telephone calls',\n",
       " 'and emails',\n",
       " 'troubleshooting system and network problems and',\n",
       " 'diagnosing and solving hardware or software faults;',\n",
       " 'maintenance of network infrastructure and architecture',\n",
       " 'maintain a thorough understanding of the basics behind',\n",
       " 'the internet and its workings (dns, security, ip routing,',\n",
       " 'http, vpn, email routing, spam, etc.']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_text = extract_text('Haymen CV.pdf')\n",
    "extract_experience(resume_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd263f-a67d-4c9e-995f-dbf2fcf75e2f",
   "metadata": {},
   "source": [
    "# Combine code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5669cb5e-6332-496e-b0a6-637d934a5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_items(input_list):\n",
    "    output_list = []\n",
    "    for item in input_list:\n",
    "        split_items = item.split('\\n')\n",
    "        # print('item', item)\n",
    "        # print('split_items', split_items)\n",
    "        output_list.extend(split_items)\n",
    "    return output_list\n",
    "def extract_experience_section(resume_text):\n",
    "    resume_headings = [\n",
    "        \"education\",\n",
    "        \"contact information\",\n",
    "        \"contact\",\n",
    "        \"objective or summary\",\n",
    "        \"skills\",\n",
    "        \"certifications\",\n",
    "        \"projects\",\n",
    "        \"volunteer work\",\n",
    "        \"awards and honors\",\n",
    "        \"languages\",\n",
    "        \"summary\",\n",
    "        \"skills &\",\n",
    "        \"expertise\",\n",
    "        \"languagues\",\n",
    "        \"interests\"\n",
    "    ]\n",
    "\n",
    "    resume_text_list = resume_text.split(\"\\n\\n\")\n",
    "    resume_text_list = [item.strip() for item in resume_text_list]\n",
    "    # resume_text_list = [item.split(\"\\n\") for item in resume_text_list]\n",
    "    resume_text_list = split_list_items(resume_text_list)\n",
    "    resume_text_list = [item.replace('\\xa0', ' ') for item in resume_text_list]\n",
    "    resume_text_list = [item.lower() for item in resume_text_list]\n",
    "    \n",
    "    result_string = ' '.join(resume_text_list)\n",
    "\n",
    "    \n",
    "    # print('resume_text_list:   ', resume_text_list)\n",
    "    exp_sen = \"\"\n",
    "    if \"experience\" in resume_text_list:\n",
    "        exp_ind = resume_text_list.index('experience')\n",
    "        for section in resume_text_list:\n",
    "            if section.lower() in resume_headings:\n",
    "                sec_ind = resume_text_list.index(section)\n",
    "                # print('******* resume_text_list[sec_ind]', resume_text_list[sec_ind])\n",
    "                # print('******* resume_text_list[exp_ind]', resume_text_list[exp_ind])\n",
    "                \n",
    "                # print('******* exp_ind', exp_ind)\n",
    "                # print('******* sec_ind', sec_ind)\n",
    "                \n",
    "                if exp_ind < sec_ind:\n",
    "                    only_exp = resume_text_list[exp_ind:sec_ind]\n",
    "                    # print('####### if only_exp: ', only_exp)\n",
    "                else:\n",
    "                    only_exp = resume_text_list[exp_ind:]\n",
    "                    exists = any(item in only_exp for item in resume_headings)\n",
    "                    if exists:\n",
    "                        # print('if exists', exists)\n",
    "                    \n",
    "                        # print('####### else only_exp: ', only_exp)\n",
    "                        # if \"experience\" in only_exp:\n",
    "                        exp_ind2 = only_exp.index('experience')\n",
    "                        for j in only_exp:\n",
    "                            if j.lower() in resume_headings:\n",
    "                                # print('sub section: ', j)\n",
    "                                sec_ind2 = only_exp.index(j)\n",
    "                                # print('******* 2222resume_text_list[sec_ind]', only_exp[sec_ind2])\n",
    "                                # print('******* 2222resume_text_list[exp_ind]', only_exp[exp_ind2])\n",
    "                                \n",
    "                                # print('******* 2222exp_ind', exp_ind2)\n",
    "                                # print('******* 2222sec_ind', sec_ind2)\n",
    "                                if exp_ind2 < sec_ind2:\n",
    "                                    only_exp2 = only_exp[exp_ind2:sec_ind2]\n",
    "                                    # print('*************** *####### if only_exp: ', only_exp2)\n",
    "                                    # exp_sen = ', '.join(only_exp2)\n",
    "                                    # print('******** only_exp2', only_exp2, '\\n\\n')\n",
    "                                    # print('only_exp2', only_exp2)\n",
    "                                    return only_exp2\n",
    "                                break\n",
    "                                    # if only_exp2:\n",
    "                                    #     exp_sen = ', '.join(only_exp2)\n",
    "                                    # break\n",
    "                            \n",
    "                    else:\n",
    "                        # exp_sen = ', '.join(only_exp)\n",
    "                        return only_exp\n",
    "                    break\n",
    "    else:\n",
    "        # exp_sen = '\\n'.join(resume_text_list)\n",
    "        resume_text_list\n",
    "\n",
    "# Function to convert months to lowercase\n",
    "def convert_months_to_lowercase(pattern):\n",
    "    months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "    for month in months:\n",
    "        pattern = re.sub(month, month.lower(), pattern)\n",
    "    return pattern\n",
    "    \n",
    "def calculate_months(date_range):\n",
    "    # Remove unnecessary characters and split the date range\n",
    "    date_range = date_range[0]\n",
    "    start_date_str, end_date_str = date_range.split(' - ')\n",
    "\n",
    "    # Define a dictionary to convert month names to numbers\n",
    "    month_dict = {\n",
    "        'january': 1, 'february': 2, 'march': 3, 'april': 4, \n",
    "        'may': 5, 'june': 6, 'july': 7, 'august': 8, \n",
    "        'september': 9, 'october': 10, 'november': 11, 'december': 12\n",
    "    }\n",
    "\n",
    "    # Parse the start date\n",
    "    start_month_str, start_year_str = start_date_str.split(' ')\n",
    "    start_month = month_dict[start_month_str.lower()]\n",
    "    start_year = int(start_year_str)\n",
    "    start_date = datetime(start_year, start_month, 1)\n",
    "\n",
    "    # Parse the end date\n",
    "    if end_date_str.lower() == 'present':\n",
    "        end_date = datetime.now()\n",
    "    else:\n",
    "        end_month_str, end_year_str = end_date_str.split(' ')\n",
    "        end_month = month_dict[end_month_str.lower()]\n",
    "        end_year = int(end_year_str)\n",
    "        end_date = datetime(end_year, end_month, 1)\n",
    "\n",
    "    # Calculate the difference in months\n",
    "    total_months = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month) + 1\n",
    "\n",
    "    return total_months\n",
    "\n",
    "\n",
    "\n",
    "def extract_experience(resume_text):\n",
    "    resume_text_list = extract_experience_section(resume_text)\n",
    "    print('########### resume_text_list', resume_text_list, '\\n\\n\\n')\n",
    "    result_string = ' '.join(resume_text_list)\n",
    "    # print('########### result_string', result_string, '\\n\\n\\n')\n",
    "    \n",
    "    \n",
    "    # Regular expression to match the format \"Month Year - Month Year\"\n",
    "         # date_pattern1 = r'(?:January|February|March|April|May|June|July|August|September|October|November|December) \\d{4} - present'\n",
    "    \n",
    "    # date_pattern2 = r'(?:January|February|March|April|May|June|July|August|September|October|November|December) \\d{4} - (?:January|February|March|April|May|June|July|August|September|October|November|December) \\d{4}'\n",
    "    \n",
    "    # date_pattern3 = r'(?:January|February|March|April|May|June|July|August|September|October|November|December) \\d{4}'\n",
    "\n",
    "    date_pattern1 = r'\\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} - present'\n",
    "    # date_pattern2 = r'\\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} - (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4}'\n",
    "    date_pattern2 = r'\\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4} - \\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4}'\n",
    "    # date_pattern3 = r'\\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4}'\n",
    "    date_pattern3 = r'\\d{2} (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4}'\n",
    "    date_pattern4 = r'\\d{1,2} (?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec) \\d{4} - present'\n",
    "    date_pattern5 = r'\\d{1,2} (?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec) \\d{4} - \\d{1,2} (?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec) \\d{4}'\n",
    "    date_pattern6 = r'\\d{1,2} (?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec) \\d{4}'\n",
    "    \n",
    "    # Convert patterns\n",
    "    date_pattern1 = convert_months_to_lowercase(date_pattern1)\n",
    "    date_pattern2 = convert_months_to_lowercase(date_pattern2)\n",
    "    date_pattern3 = convert_months_to_lowercase(date_pattern3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    combined_pattern = f'({date_pattern1})|({date_pattern2})|({date_pattern3})|({date_pattern4})|({date_pattern5})|({date_pattern6})'\n",
    "    \n",
    "    \n",
    "    matches = re.findall(combined_pattern, result_string)\n",
    "    \n",
    "    matches = [item for tup in matches for item in tup if item]\n",
    "    \n",
    "    # Print matches\n",
    "    print('\\n\\n********* matches: ', matches, '\\n\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "    months = 0\n",
    "    print('******** matches', matches)\n",
    "    for i in matches:\n",
    "        months = calculate_months([i]) + months\n",
    "    years, months = divmod(months, 12)\n",
    "    return years, months\n",
    "    # if any('present' in date_range for date_range in matches):\n",
    "    #     for i in matches[1:]:\n",
    "    #         months = calculate_months([i]) + months\n",
    "    #     years, months = divmod(months, 12)\n",
    "    #     return years, months\n",
    "    # else:\n",
    "    #     print(\"The term 'present' is not in the list.\")\n",
    "    #     for i in matches:\n",
    "    #         months = calculate_months([i]) + months\n",
    "    #     years, months = divmod(months, 12)\n",
    "    #     return years, months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "32738a66-a779-481f-bc3d-3c412d38e353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### resume_text_list ['experience', '•  performed lidar data annotation for vehicle and lane both. ', '•  manual quality control of annotated data. ', '•  developed perception tools between various annotators. ', '•  developed automated quality control tools using master to slave concept. ', '•  blooming data annotating on robot operating system (ros) to enhance the quality of next sensor. ', '•  currently, working on object detection through machine learning using pointnet2 using different algorithms like', 'pv-rcnn, second.', 'pso mentorship program it department as data scientist ', '(4 may 2021 – 26 jan 2022)', 'project i dispenser unit automation', '•  manage a team of 5 people for this project. also have meeting with them to discuss potential', 'situations for the project.', '•  maintaining and updating database for dispenser units. ', '•  tackling data wrangling issues in order to normalize the data for analysis. ', '•  statistical analysis and visualization of the data to determine the anomalies, trends and summarizing', 'the details with useful insights for decision making.', '•  carry out review of results and accomplishment of project post implementation based on data. ', '•  this project manages to keep a close eye on gas stations while eliminating close to 80% of the ', 'gasoline stockpile. it made it possible to alter fuel pricing online rather than at the pump.', 'project ii rfid based queue management system (qms)', 'logic design of rfid based smart queue management system.', '• ', '•  testing and deployment of qms using radio frequency tags implemented on vehicles. ', '•  carrying out the performance review of qms using statistical analysis.', 'aptech computer education ', '(28 jan 2021- march 7)', 'delivered theoretical & practical knowledge of programming.', '•  to grasp the basics of how a programming language functions, procedural, functional, and logical programming', 'languages are taught thru c programming.', '•  c# was used to implement object-oriented programming in order to better comprehend code reuse and data', 'privacy.', '•  taught sql server database skills, including how to update and maintain databases.', 'references can be furnished upon request.', ''] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********* matches:  ['4 may 2021', '26 jan 2022', '28 jan 2021'] \n",
      "\n",
      "\n",
      "******** matches ['4 may 2021', '26 jan 2022', '28 jan 2021']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m resume_text \u001b[38;5;241m=\u001b[39m extract_text(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMuhammad_Adil_Sarki-1(Data Science).pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m years, months \u001b[38;5;241m=\u001b[39m \u001b[43mextract_experience\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresume_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m experience \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00myears\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m years \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonths\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m months\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal Experience: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperience\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[73], line 178\u001b[0m, in \u001b[0;36mextract_experience\u001b[1;34m(resume_text)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m******** matches\u001b[39m\u001b[38;5;124m'\u001b[39m, matches)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m matches:\n\u001b[1;32m--> 178\u001b[0m     months \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_months\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m months\n\u001b[0;32m    179\u001b[0m years, months \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(months, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m years, months\n",
      "Cell \u001b[1;32mIn[73], line 102\u001b[0m, in \u001b[0;36mcalculate_months\u001b[1;34m(date_range)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_months\u001b[39m(date_range):\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;66;03m# Remove unnecessary characters and split the date range\u001b[39;00m\n\u001b[0;32m    101\u001b[0m     date_range \u001b[38;5;241m=\u001b[39m date_range[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m--> 102\u001b[0m     start_date_str, end_date_str \u001b[38;5;241m=\u001b[39m date_range\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# Define a dictionary to convert month names to numbers\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     month_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    106\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjanuary\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfebruary\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmarch\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapril\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m, \n\u001b[0;32m    107\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmay\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjune\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m6\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjuly\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m7\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maugust\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m8\u001b[39m, \n\u001b[0;32m    108\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseptember\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m9\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moctober\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnovember\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m11\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecember\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m12\u001b[39m\n\u001b[0;32m    109\u001b[0m     }\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "resume_text = extract_text('Muhammad_Adil_Sarki-1(Data Science).pdf')\n",
    "years, months = extract_experience(resume_text)\n",
    "experience = f'{years} years {months} months'\n",
    "print(f\"Total Experience: {experience}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593dec4-501b-4b0f-a7ef-852705d02050",
   "metadata": {},
   "outputs": [],
   "source": [
    "['muhammad adil sarki ', '+923362166817/aadiisarki@gmail.com', 'summary ', '➢  a distinguished professional with more than 2 years of experience in data science with hands on analysing large', 'data sets and coming with data driven insights. worked with teams of 6-8 team members.', '➢  core competencies in data annotation, data wrangling, data visualisation, automating process, machine', 'learning, deep learning algorithms.', '➢  bachelor of engineering - computer system engineering from dawood university of engineering and technology', 'education', '(duet), pakistan. ', 'karachi [2017-2020] cgpa: 3.88(1st position).', '➢', 'intermediate (pre-engineering), govt degree college malir cantt ', 'september 2013 - may 2015. percentage 73.83%.', '➢  matriculation board bsek may 2011- 2013. percentage 83.23%', '➢  android app development from advance technical training center. ', '➢  presidential initiative for artificial intelligence & computing (piaic) for ai. ', '➢  python for machine learning from coursera', 'certification', 'languages', 'libraries', 'tools', 'frameworks', 'database', 'skills', 'c/c++ (basic), java, python.', 'pandas, numpy, matplotlib, beautiful-soup, scrapy, scikit-learn,     seaborn, tensor-flow, ', 'keras.', 'netbeans, anaconda, vs code, power bi, pycharm', 'py-torch, django, flask.', 'mysql, sqlite.', 'ml and dl models', 'regression, arma and arima time series model, 3d object detection i,e opennet2.', 'version control', 'git', 'operating system', 'robotic operating system, linux', 'project management', 'agile process i.e., redmine', 'storage', 'nas', 'covlov.ai as jnr data scientist ', '(27 jan 2022 – present)', 'experience', '•  performed lidar data annotation for vehicle and lane both. ', '•  manual quality control of annotated data. ', '•  developed perception tools between various annotators. ', '•  developed automated quality control tools using master to slave concept. ', '•  blooming data annotating on robot operating system (ros) to enhance the quality of next sensor. ', '•  currently, working on object detection through machine learning using pointnet2 using different algorithms like', 'pv-rcnn, second.', 'pso mentorship program it department as data scientist ', '(4 may 2021 – 26 jan 2022)', 'project i dispenser unit automation', '•  manage a team of 5 people for this project. also have meeting with them to discuss potential', 'situations for the project.', '•  maintaining and updating database for dispenser units. ', '•  tackling data wrangling issues in order to normalize the data for analysis. ', '•  statistical analysis and visualization of the data to determine the anomalies, trends and summarizing', 'the details with useful insights for decision making.', '•  carry out review of results and accomplishment of project post implementation based on data. ', '•  this project manages to keep a close eye on gas stations while eliminating close to 80% of the ', 'gasoline stockpile. it made it possible to alter fuel pricing online rather than at the pump.', 'project ii rfid based queue management system (qms)', 'logic design of rfid based smart queue management system.', '• ', '•  testing and deployment of qms using radio frequency tags implemented on vehicles. ', '•  carrying out the performance review of qms using statistical analysis.', 'aptech computer education ', '(28 jan 2021- march 7)', 'delivered theoretical & practical knowledge of programming.', '•  to grasp the basics of how a programming language functions, procedural, functional, and logical programming', 'languages are taught thru c programming.', '•  c# was used to implement object-oriented programming in order to better comprehend code reuse and data', 'privacy.', '•  taught sql server database skills, including how to update and maintain databases.', 'references can be furnished upon request.', '']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fea55b-e2dc-49fd-9059-9f76d53dca05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb838a64-7c46-4978-8297-2d761f2157b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def calculate_months(date_range):\n",
    "    # Remove unnecessary characters and split the date range\n",
    "    date_range = date_range[0]\n",
    "    start_date_str, end_date_str = date_range.split(' - ')\n",
    "\n",
    "    # Define a dictionary to convert month names to numbers\n",
    "    month_dict = {\n",
    "        'january': 1, 'february': 2, 'march': 3, 'april': 4, \n",
    "        'may': 5, 'june': 6, 'july': 7, 'august': 8, \n",
    "        'september': 9, 'october': 10, 'november': 11, 'december': 12\n",
    "    }\n",
    "\n",
    "    # Parse the start date\n",
    "    start_month_str, start_year_str = start_date_str.split(' ')\n",
    "    start_month = month_dict[start_month_str.lower()]\n",
    "    start_year = int(start_year_str)\n",
    "    start_date = datetime(start_year, start_month, 1)\n",
    "\n",
    "    # Parse the end date\n",
    "    if end_date_str.lower() == 'present':\n",
    "        end_date = datetime.now()\n",
    "    else:\n",
    "        end_month_str, end_year_str = end_date_str.split(' ')\n",
    "        end_month = month_dict[end_month_str.lower()]\n",
    "        end_year = int(end_year_str)\n",
    "        end_date = datetime(end_year, end_month, 1)\n",
    "\n",
    "    # Calculate the difference in months\n",
    "    total_months = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month) + 1\n",
    "\n",
    "    return total_months\n",
    "\n",
    "# Example usage\n",
    "date_range = ['january 2017 - september 2018']\n",
    "print(calculate_months(date_range))  # Output: 21\n",
    "\n",
    "date_range = ['february 2022 - present']\n",
    "print(calculate_months(date_range))  # Output: 9 (assuming the current month is August 2024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8393b961-bb10-46d6-978b-0c2236d21ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "********* matches:  ['4 may 2021', '26 jan 2022'] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_string = '4 may 2021 – 26 jan 2022'\n",
    "date_pattern1 = r'\\d{1,2} (?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec) \\d{4} - present'\n",
    "date_pattern2 = r'\\d{1,2} (?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec) \\d{4} - \\d{1,2} (?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec) \\d{4}'\n",
    "date_pattern3 = r'\\d{1,2} (?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec) \\d{4}'\n",
    "date_pattern4 = r'\\d{1,2} (?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec) \\d{1}'\n",
    "\n",
    "\n",
    "# Combine the patterns\n",
    "combined_pattern = f'({date_pattern1})|({date_pattern2})|({date_pattern3})'\n",
    "\n",
    "# Sample string to search\n",
    "result_string = \"'pso mentorship program it department as data scientist ', '(4 may 2021 – 26 jan 2022)'\"\n",
    "\n",
    "# Find matches\n",
    "matches = re.findall(combined_pattern, result_string)\n",
    "\n",
    "# Flatten the list of tuples\n",
    "matches = [item for tup in matches for item in tup if item]\n",
    "\n",
    "# Print matches\n",
    "print('\\n\\n********* matches: ', matches, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "137d594f-e0ac-4c22-acea-bed25b533e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def calculate_months(date_range):\n",
    "    # Remove unnecessary characters and split the date range\n",
    "    start_date_str, end_date_str = date_range\n",
    "\n",
    "    # Define a dictionary to convert month names to numbers\n",
    "    month_dict = {\n",
    "        'jan': 1, 'january': 1, 'february': 2, 'march': 3, 'april': 4, \n",
    "        'may': 5, 'june': 6, 'july': 7, 'august': 8, \n",
    "        'september': 9, 'october': 10, 'november': 11, 'december': 12\n",
    "    }\n",
    "\n",
    "    def parse_date(date_str):\n",
    "        parts = date_str.split(' ')\n",
    "        if len(parts) == 3:  # Format: '4 may 2021'\n",
    "            day = int(parts[0])\n",
    "            month = month_dict[parts[1].lower()]\n",
    "            year = int(parts[2])\n",
    "            return datetime(year, month, day)\n",
    "        elif len(parts) == 2:  # Format: 'may 2021'\n",
    "            month = month_dict[parts[0].lower()]\n",
    "            year = int(parts[1])\n",
    "            return datetime(year, month, 1)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid date format\")\n",
    "\n",
    "    # Parse the start date\n",
    "    start_date = parse_date(start_date_str)\n",
    "\n",
    "    # Parse the end date\n",
    "    if end_date_str.lower() == 'present':\n",
    "        end_date = datetime.now()\n",
    "    else:\n",
    "        end_date = parse_date(end_date_str)\n",
    "\n",
    "    # Calculate the difference in months\n",
    "    total_months = (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month) + 1\n",
    "\n",
    "    return total_months\n",
    "\n",
    "# Example usage\n",
    "date_range1 = 'january 2017 - september 2018'.split(' - ')\n",
    "date_range2 = ['4 may 2021', '26 jan 2022']\n",
    "\n",
    "print(calculate_months(date_range1))  # Output: 21\n",
    "print(calculate_months(date_range2))  # Output: 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f3547f-a02a-4158-8d8e-1bc1e7f74f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
